{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Machine Learning Project\n",
    "## Project: Titanic - Machine Learning from Disaster \n",
    "\n",
    "The problem to be solved is to predict the passengers that survive the Titanic. The goal is to use passenger characteristics and location to determine if a passenger is likely to die or survive. Based off the Kaggle prompt and the expected typed of output, this problem is a supervised classification problem. A potential way to solve this problem is to use a neural network classifier. For the sake of exploration, I hope to use other machine learning techniques like random forests and support vector machines to classify the passengers aboard the Titanic. The benchmark model will be a simple linear regression. The score to determine usefulness of the solution is the accuracy, the percentage of passengers correctly predicted.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked']\n",
      "Titanic Disaster training dataset has 712 rows of data with 10 variables each.\n",
      "Titanic Disaster testing dataset has 331 rows of data with 9 variables each.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "#Import Train Data\n",
    "#Grab train_x data excluding Survivors\n",
    "train_df = pd.read_csv('Data/train.csv')\n",
    "train_df = train_df.drop('Cabin', axis =1)\n",
    "train_df = train_df.drop('Name', axis = 1)\n",
    "train_df = train_df.dropna()\n",
    "train_x = train_df.drop('Survived', axis = 1)\n",
    "\n",
    "#Grab train_y only with Survivors\n",
    "features = list(train_df)\n",
    "print features\n",
    "train_y = train_df.drop(features, axis = 1)\n",
    "\n",
    "\n",
    "#Import Test Data\n",
    "test_df = pd.read_csv('Data/test.csv')\n",
    "test_df = test_df.drop('Cabin', axis = 1)\n",
    "test_df = test_df.drop('Name', axis =1)\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "# Success Check\n",
    "print \"Titanic Disaster training dataset has {} rows of data with {} variables each.\".format(*train_df.shape)\n",
    "print \"Titanic Disaster testing dataset has {} rows of data with {} variables each.\".format(*test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data Exploration\n",
    "\n",
    "The data can be described as\n",
    "\n",
    "1. survival = Survival\n",
    "1. pclass = Ticket class\n",
    "1. sex = Sex\t\n",
    "1. Age = Age in years\t\n",
    "1. sibsp =\t# of siblings / spouses aboard the Titanic\t\n",
    "1. parch =\t# of parents / children aboard the Titanic\t\n",
    "1. ticket =\tTicket number\t\n",
    "1. fare = Passenger fare\t\n",
    "1. cabin =\tCabin number\t\n",
    "1. embarked =\tPort of Embarkation\n",
    "\n",
    "I used Pandas describe() function to explore the numbers data. However, this function does not take into consideration the data that involves strings such as: 'Name', 'Sex', 'Ticket', 'Cabin', and 'Embarked'. 'Sex' looks like a good candidate to change 'Male' and \"Female' to binary values using one hot encoding. PassengerId doesn't mean much based on these statistics as its just a unique identifier for each individual. Pclass seems to show that most people were of Pclass 2 or 3. Age shows that most people were approximately 30 years old. The minimum and maximum also suggests that there are elderly and children on board. The count of the age being lower than other features indicates that there is missing data that has to be dealt with. Sibsp and Parch show that the majority of passengers came alone or possibly with friends depending on what the data represents. Fare seems to indicate that there were 3 ticket classes as the 25-75% quartiles seem fairly different. It is interesting to note that the mean seems to be in the 75% quartile of data possibly due to a few very large fares indicated by the max being $512. Cabin is most likely going to be removed as a feature because there is too much missing data and it would be hard to make conclusions when most people's information is unknown. It seems logical to remove Name as they are all unique identifiers represented by the PassengerID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>448.589888</td>\n",
       "      <td>0.404494</td>\n",
       "      <td>2.240169</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0.514045</td>\n",
       "      <td>0.432584</td>\n",
       "      <td>34.567251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>258.683191</td>\n",
       "      <td>0.491139</td>\n",
       "      <td>0.836854</td>\n",
       "      <td>14.492933</td>\n",
       "      <td>0.930692</td>\n",
       "      <td>0.854181</td>\n",
       "      <td>52.938648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>222.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.645850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>677.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   712.000000  712.000000  712.000000  712.000000  712.000000   \n",
       "mean    448.589888    0.404494    2.240169   29.642093    0.514045   \n",
       "std     258.683191    0.491139    0.836854   14.492933    0.930692   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     222.750000    0.000000    1.000000   20.000000    0.000000   \n",
       "50%     445.000000    0.000000    2.000000   28.000000    0.000000   \n",
       "75%     677.250000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    5.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  712.000000  712.000000  \n",
       "mean     0.432584   34.567251  \n",
       "std      0.854181   52.938648  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    8.050000  \n",
       "50%      0.000000   15.645850  \n",
       "75%      1.000000   33.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grab list of keypoint names\n",
    "#print features\n",
    "print train_df.isnull().sum()\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 9)\n",
      "(712, 0)\n",
      "     PassengerId  Pclass  Sex   Age  SibSp  Parch            Ticket      Fare  \\\n",
      "0              1       3    0  22.0      1      0         A/5 21171    7.2500   \n",
      "1              2       1    1  38.0      1      0          PC 17599   71.2833   \n",
      "2              3       3    1  26.0      0      0  STON/O2. 3101282    7.9250   \n",
      "3              4       1    1  35.0      1      0            113803   53.1000   \n",
      "4              5       3    0  35.0      0      0            373450    8.0500   \n",
      "6              7       1    0  54.0      0      0             17463   51.8625   \n",
      "7              8       3    0   2.0      3      1            349909   21.0750   \n",
      "8              9       3    1  27.0      0      2            347742   11.1333   \n",
      "9             10       2    1  14.0      1      0            237736   30.0708   \n",
      "10            11       3    1   4.0      1      1           PP 9549   16.7000   \n",
      "11            12       1    1  58.0      0      0            113783   26.5500   \n",
      "12            13       3    0  20.0      0      0         A/5. 2151    8.0500   \n",
      "13            14       3    0  39.0      1      5            347082   31.2750   \n",
      "14            15       3    1  14.0      0      0            350406    7.8542   \n",
      "15            16       2    1  55.0      0      0            248706   16.0000   \n",
      "16            17       3    0   2.0      4      1            382652   29.1250   \n",
      "18            19       3    1  31.0      1      0            345763   18.0000   \n",
      "20            21       2    0  35.0      0      0            239865   26.0000   \n",
      "21            22       2    0  34.0      0      0            248698   13.0000   \n",
      "22            23       3    1  15.0      0      0            330923    8.0292   \n",
      "23            24       1    0  28.0      0      0            113788   35.5000   \n",
      "24            25       3    1   8.0      3      1            349909   21.0750   \n",
      "25            26       3    1  38.0      1      5            347077   31.3875   \n",
      "27            28       1    0  19.0      3      2             19950  263.0000   \n",
      "30            31       1    0  40.0      0      0          PC 17601   27.7208   \n",
      "33            34       2    0  66.0      0      0        C.A. 24579   10.5000   \n",
      "34            35       1    0  28.0      1      0          PC 17604   82.1708   \n",
      "35            36       1    0  42.0      1      0            113789   52.0000   \n",
      "37            38       3    0  21.0      0      0        A./5. 2152    8.0500   \n",
      "38            39       3    1  18.0      2      0            345764   18.0000   \n",
      "..           ...     ...  ...   ...    ...    ...               ...       ...   \n",
      "856          857       1    1  45.0      1      1             36928  164.8667   \n",
      "857          858       1    0  51.0      0      0            113055   26.5500   \n",
      "858          859       3    1  24.0      0      3              2666   19.2583   \n",
      "860          861       3    0  41.0      2      0            350026   14.1083   \n",
      "861          862       2    0  21.0      1      0             28134   11.5000   \n",
      "862          863       1    1  48.0      0      0             17466   25.9292   \n",
      "864          865       2    0  24.0      0      0            233866   13.0000   \n",
      "865          866       2    1  42.0      0      0            236852   13.0000   \n",
      "866          867       2    1  27.0      1      0     SC/PARIS 2149   13.8583   \n",
      "867          868       1    0  31.0      0      0          PC 17590   50.4958   \n",
      "869          870       3    0   4.0      1      1            347742   11.1333   \n",
      "870          871       3    0  26.0      0      0            349248    7.8958   \n",
      "871          872       1    1  47.0      1      1             11751   52.5542   \n",
      "872          873       1    0  33.0      0      0               695    5.0000   \n",
      "873          874       3    0  47.0      0      0            345765    9.0000   \n",
      "874          875       2    1  28.0      1      0         P/PP 3381   24.0000   \n",
      "875          876       3    1  15.0      0      0              2667    7.2250   \n",
      "876          877       3    0  20.0      0      0              7534    9.8458   \n",
      "877          878       3    0  19.0      0      0            349212    7.8958   \n",
      "879          880       1    1  56.0      0      1             11767   83.1583   \n",
      "880          881       2    1  25.0      0      1            230433   26.0000   \n",
      "881          882       3    0  33.0      0      0            349257    7.8958   \n",
      "882          883       3    1  22.0      0      0              7552   10.5167   \n",
      "883          884       2    0  28.0      0      0  C.A./SOTON 34068   10.5000   \n",
      "884          885       3    0  25.0      0      0   SOTON/OQ 392076    7.0500   \n",
      "885          886       3    1  39.0      0      5            382652   29.1250   \n",
      "886          887       2    0  27.0      0      0            211536   13.0000   \n",
      "887          888       1    1  19.0      0      0            112053   30.0000   \n",
      "889          890       1    0  26.0      0      0            111369   30.0000   \n",
      "890          891       3    0  32.0      0      0            370376    7.7500   \n",
      "\n",
      "     Embarked  \n",
      "0           0  \n",
      "1           1  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "6           0  \n",
      "7           0  \n",
      "8           0  \n",
      "9           1  \n",
      "10          0  \n",
      "11          0  \n",
      "12          0  \n",
      "13          0  \n",
      "14          0  \n",
      "15          0  \n",
      "16          2  \n",
      "18          0  \n",
      "20          0  \n",
      "21          0  \n",
      "22          2  \n",
      "23          0  \n",
      "24          0  \n",
      "25          0  \n",
      "27          0  \n",
      "30          1  \n",
      "33          0  \n",
      "34          1  \n",
      "35          0  \n",
      "37          0  \n",
      "38          0  \n",
      "..        ...  \n",
      "856         0  \n",
      "857         0  \n",
      "858         1  \n",
      "860         0  \n",
      "861         0  \n",
      "862         0  \n",
      "864         0  \n",
      "865         0  \n",
      "866         1  \n",
      "867         0  \n",
      "869         0  \n",
      "870         0  \n",
      "871         0  \n",
      "872         0  \n",
      "873         0  \n",
      "874         1  \n",
      "875         1  \n",
      "876         0  \n",
      "877         0  \n",
      "879         1  \n",
      "880         0  \n",
      "881         0  \n",
      "882         0  \n",
      "883         0  \n",
      "884         0  \n",
      "885         2  \n",
      "886         0  \n",
      "887         0  \n",
      "889         1  \n",
      "890         2  \n",
      "\n",
      "[712 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#Show dimensions\n",
    "print train_x.shape\n",
    "print train_y.shape\n",
    "\n",
    "#Change female and male to integer values where male = 0 and female = 1\n",
    "train_x['Sex'] = train_x['Sex'].map({'female':1, 'male': 0})\n",
    "train_x['Embarked'] = train_x['Embarked'].map({'S':0, 'C':1, 'Q':2})\n",
    "print train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: SOTON/OQ 392076",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-41e855057c7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mregr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mregr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[1;31m#error_vals = mean_squared_error(y_test, regr.predict(X_test))**0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;31m#print \"The benchmark root mean squared error is %s\" % error_vals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Nicholas\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 512\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Nicholas\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32mC:\\Users\\Nicholas\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"O\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: SOTON/OQ 392076"
     ]
    }
   ],
   "source": [
    "regr = LinearRegression()\n",
    "regr.fit(train_x,train_y)\n",
    "#error_vals = mean_squared_error(y_test, regr.predict(X_test))**0.5\n",
    "#print \"The benchmark root mean squared error is %s\" % error_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
